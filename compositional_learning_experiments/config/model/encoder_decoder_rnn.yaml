model:
  name: EncoderDecoderRNN
  rnn_base: lstm
  d_model: 256
  num_layers: 2
  dropout: 0.0
  bidirectional_encoder: true

training:
  batch_size: 4
  learning_rate: 1.0e-3

trainer:
  gradient_clip_val: 5
