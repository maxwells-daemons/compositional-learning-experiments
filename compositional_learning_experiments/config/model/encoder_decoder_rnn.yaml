model_meta:
  name: EncoderDecoderRNN
  domain: Seq2Seq

model:
  rnn_base: lstm
  d_model: 256
  num_layers: 2
  dropout: 0.0
  bidirectional_encoder: true

training:
  batch_size: 128
  learning_rate: 6.0e-4

trainer:
  gradient_clip_val: 1.0
